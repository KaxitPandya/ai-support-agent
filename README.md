# ğŸ§  AI Support Agent - Knowledge Assistant

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4o-green.svg)](https://openai.com/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109+-00a393.svg)](https://fastapi.tiangolo.com/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.31+-FF4B4B.svg)](https://streamlit.io/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> **Production-ready RAG (Retrieval-Augmented Generation) system that helps support teams resolve customer tickets efficiently using AI and relevant documentation.**

Built with FastAPI, OpenAI GPT-4o, FAISS vector database, and Streamlit - featuring advanced hybrid search, conversation memory, and Model Context Protocol (MCP) structured prompting.

---

## ğŸ¯ What This Does

Transform customer support tickets into accurate, policy-compliant responses using AI:

**Input:**
```json
{
  "ticket_text": "My domain was suspended and I didn't get any notice. How can I reactivate it?"
}
```

**Output (MCP-Compliant):**
```json
{
  "answer": "Your domain may have been suspended due to WHOIS verification failure or policy violation. To reactivate: 1) Log into your domain management portal, 2) Navigate to 'My Domains' and check suspension details, 3) Update your WHOIS information and verify your email. Reactivation typically takes 24-48 hours after verification.",
  "references": [
    "Policy: Domain Suspension Guidelines, Section 4.2 - Reactivation Process",
    "Policy: Domain Suspension Guidelines, Section 4.3 - Communication"
  ],
  "action_required": "customer_action_required"
}
```

---

## âœ¨ Key Features

| Feature | Description |
|---------|-------------|
| ğŸ” **Hybrid Search** | Combines semantic (FAISS) + keyword (BM25) search with cross-encoder reranking |
| ğŸ§  **Conversation Memory** | Short-term + long-term memory for consistent, context-aware responses |
| ğŸ“š **Dynamic Knowledge Base** | Upload documents via UI or API without code changes |
| ğŸ¨ **Beautiful Web UI** | Professional Streamlit interface with analytics and debugging tools |
| ğŸ¤– **MCP-Compliant** | Structured prompt engineering with role, context, task, and output schema |
| ğŸ“Š **RAG Inspector** | Debug and visualize the retrieval pipeline in real-time |
| ğŸ§ª **Semantic Chunking** | Topic-aware document splitting using embeddings (not character-based) |
| ğŸš€ **Production Ready** | 114+ unit tests, Docker support, comprehensive error handling |
| âš¡ **FastAPI Backend** | Async API with automatic OpenAPI docs at `/docs` |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Customer Support Ticket                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       RAG Pipeline                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  Query     â”‚â†’ â”‚   Hybrid    â”‚â†’ â”‚   Context    â”‚            â”‚
â”‚  â”‚ Embedding  â”‚  â”‚   Search    â”‚  â”‚  Augmented   â”‚            â”‚
â”‚  â”‚            â”‚  â”‚ (Semantic+  â”‚  â”‚    Prompt    â”‚            â”‚
â”‚  â”‚            â”‚  â”‚   BM25)     â”‚  â”‚    (MCP)     â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   OpenAI GPT-4o / GPT-4o-mini                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Structured JSON Response (Answer + References)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Core Technologies:**
- **LLM:** OpenAI GPT-4o / GPT-4o-mini
- **Vector DB:** FAISS (Facebook AI Similarity Search)
- **Embeddings:** Sentence Transformers (all-MiniLM-L6-v2)
- **API:** FastAPI (async Python web framework)
- **UI:** Streamlit (interactive data apps)
- **Search:** Hybrid (semantic + BM25 keyword + cross-encoder reranking)

---

## ğŸš€ Quick Start

### Option 1: Docker (Recommended)

```bash
# 1. Clone the repository
git clone https://github.com/KaxitPandya/ai-support-agent.git
cd ai-support-agent

# 2. Create .env file and add your OpenAI API key
cp env.example .env
# Edit .env and set: OPENAI_API_KEY=sk-your-key-here

# 3. Start with Docker Compose
docker-compose up --build

# 4. Access the application
# - API: http://localhost:8000
# - API Docs: http://localhost:8000/docs
```

### Option 2: Local Python Environment

```bash
# 1. Clone the repository
git clone https://github.com/KaxitPandya/ai-support-agent.git
cd ai-support-agent

# 2. Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Setup environment
cp env.example .env
# Edit .env and add your OpenAI API key

# 5. Run Streamlit UI (easiest way to start)
streamlit run streamlit_app.py
# Opens at http://localhost:8501

# OR run FastAPI backend
uvicorn src.main:app --reload --port 8000
# API at http://localhost:8000
```

---

## ğŸŒ Deployment Options

### Deploy to Streamlit Cloud (Free, 1-Click)

1. **Fork this repository** to your GitHub account

2. **Go to [share.streamlit.io](https://share.streamlit.io)** and click "New app"

3. **Select your repository:**
   - Repository: `YOUR-USERNAME/ai-support-agent`
   - Branch: `main`
   - Main file: `streamlit_app.py`

4. **Add secrets** in Streamlit Cloud dashboard (Settings â†’ Secrets):
   ```toml
   OPENAI_API_KEY = "sk-your-actual-key-here"
   OPENAI_MODEL = "gpt-4o-mini"
   OPENAI_TEMPERATURE = "0.3"
   OPENAI_MAX_TOKENS = "1024"
   TOP_K_RESULTS = "5"
   SIMILARITY_THRESHOLD = "0.3"
   ```

5. **Click Deploy** - Your app will be live at `https://your-app.streamlit.app` ğŸ‰

### Deploy with Docker

See the [Docker Deployment](#-docker-deployment) section below.

---

## ğŸ“– API Reference

### Resolve a Support Ticket

**Endpoint:** `POST /resolve-ticket`

**Request:**
```bash
curl -X POST http://localhost:8000/resolve-ticket \
  -H "Content-Type: application/json" \
  -d '{
    "ticket_text": "My domain was suspended. How can I reactivate it?"
  }'
```

**Response:**
```json
{
  "answer": "Your domain may have been suspended due to...",
  "references": ["Policy: Domain Suspension Guidelines, Section 4.2"],
  "action_required": "customer_action_required"
}
```

### Upload a Document

**Endpoint:** `POST /api/documents/upload`

```bash
curl -X POST http://localhost:8000/api/documents/upload \
  -F "file=@policy.md" \
  -F "category=Domain Policies" \
  -F "index_immediately=true"
```

### Additional Endpoints

- **Health Check:** `GET /health`
- **List Uploaded Files:** `GET /api/documents/files`
- **Delete File:** `DELETE /api/documents/files/{filename}`
- **Reindex All:** `POST /api/documents/reindex`
- **Get Stats:** `GET /api/documents/stats`

**Interactive Documentation:** http://localhost:8000/docs

---

## ğŸ¨ Web UI Features

The Streamlit interface provides:

### 1. ğŸ« Ticket Resolution
- Resolve customer tickets with AI-powered responses
- Quick examples for common scenarios
- Real-time RAG pipeline visualization
- View retrieved documents and similarity scores

### 2. ğŸ“š Knowledge Base Management
- Upload new documents (.txt, .md)
- Browse indexed documents by category
- Delete and reindex documents
- Track upload history

### 3. ğŸ”¬ RAG Inspector
- Test the retrieval pipeline with custom queries
- View MCP prompt structure
- Debug similarity scores and document ranking
- Understand how the AI generates responses

### 4. ğŸ“Š Analytics Dashboard
- Total documents indexed
- Tickets resolved count
- System configuration overview
- Performance metrics

### 5. âš™ï¸ Settings
- Adjust RAG parameters (top-k, threshold)
- Configure LLM settings (model, temperature, max tokens)
- Reset pipeline and clear session

---

## ğŸ³ Docker Deployment

### Build and Run

```bash
# Build the Docker image
docker build -t ai-support-agent .

# Run the container
docker run -d \
  -p 8000:8000 \
  -e OPENAI_API_KEY=sk-your-key-here \
  -e OPENAI_MODEL=gpt-4o-mini \
  -v $(pwd)/data:/app/data \
  --name support-agent \
  ai-support-agent

# Check logs
docker logs -f support-agent

# Stop the container
docker stop support-agent
```

### Docker Compose (Multi-Service)

```bash
# Start all services
docker-compose up -d

# View logs
docker-compose logs -f

# Stop all services
docker-compose down

# Rebuild after changes
docker-compose up --build
```

---

## ğŸ§ª Testing

### Run All Tests

```bash
# Run all 114 tests
pytest

# Run with coverage report
pytest --cov=src --cov-report=term-missing

# Run specific test file
pytest tests/test_rag.py -v

# Run with verbose output
pytest -vv
```

### Test Coverage

- âœ… **RAG Pipeline:** Context retrieval, response generation, error handling
- âœ… **Vector Store:** FAISS operations, similarity search, persistence
- âœ… **Embeddings:** Text embedding, similarity calculation
- âœ… **Hybrid Search:** Semantic + keyword search, reranking
- âœ… **Memory System:** Short-term buffer, long-term storage
- âœ… **API Endpoints:** Request validation, error responses
- âœ… **MCP Prompts:** Prompt structure, context injection

---

## ğŸ“ Project Structure

```
ai-support-agent/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ upload.py              # Document upload endpoints
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ knowledge_base.py      # Sample support docs
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py             # Pydantic models
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â””â”€â”€ mcp_prompt.py          # MCP prompt templates
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ rag.py                 # RAG pipeline orchestrator
â”‚   â”‚   â”œâ”€â”€ vector_store.py        # FAISS vector database
â”‚   â”‚   â”œâ”€â”€ embedding.py           # Sentence Transformers
â”‚   â”‚   â”œâ”€â”€ llm.py                 # OpenAI integration
â”‚   â”‚   â”œâ”€â”€ hybrid_search.py       # Hybrid search engine
â”‚   â”‚   â”œâ”€â”€ memory.py              # Conversation memory
â”‚   â”‚   â”œâ”€â”€ semantic_chunker.py    # Topic-aware chunking
â”‚   â”‚   â””â”€â”€ document_processor.py  # Document processing
â”‚   â”œâ”€â”€ config.py                  # Configuration management
â”‚   â””â”€â”€ main.py                    # FastAPI application
â”œâ”€â”€ tests/                         # 114+ unit tests
â”œâ”€â”€ streamlit_app.py               # Streamlit web UI
â”œâ”€â”€ Dockerfile                     # Docker configuration
â”œâ”€â”€ docker-compose.yml             # Docker Compose setup
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ env.example                    # Environment template
â””â”€â”€ README.md                      # This file
```

---

## âš™ï¸ Configuration

All settings are managed via environment variables. See [env.example](env.example) for all options.

### Required Settings

| Variable | Description | Example |
|----------|-------------|---------|
| `OPENAI_API_KEY` | Your OpenAI API key | `sk-...` |

### Optional Settings

| Variable | Description | Default |
|----------|-------------|---------|
| `OPENAI_MODEL` | OpenAI model name | `gpt-4o-mini` |
| `OPENAI_TEMPERATURE` | Response creativity (0-1) | `0.3` |
| `OPENAI_MAX_TOKENS` | Max response length | `1024` |
| `TOP_K_RESULTS` | Documents to retrieve | `5` |
| `SIMILARITY_THRESHOLD` | Min similarity score | `0.3` |
| `EMBEDDING_MODEL` | Sentence Transformer model | `all-MiniLM-L6-v2` |

---

## ğŸ§© How It Works

### 1. Document Indexing (One-Time Setup)
```
Documents â†’ Chunking â†’ Embedding â†’ FAISS Vector Database
```
- Documents are split into semantic chunks (topic-aware)
- Each chunk is embedded using Sentence Transformers
- Embeddings stored in FAISS for fast similarity search

### 2. Ticket Resolution (Per Query)
```
Ticket â†’ Embed â†’ Search (Hybrid) â†’ Rerank â†’ Build Prompt (MCP) â†’ LLM â†’ Response
```
- Customer ticket is embedded
- Hybrid search retrieves relevant docs (semantic + keyword)
- Cross-encoder reranks results
- MCP prompt built with context
- OpenAI generates structured response

### 3. Model Context Protocol (MCP)

MCP is a structured prompt engineering pattern with four sections:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ROLE: Expert support assistant identity     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ CONTEXT: Retrieved documents from RAG       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TASK: Customer ticket + instructions        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ OUTPUT: JSON schema specification           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

This ensures:
- **Consistency:** Same structure every time
- **Grounding:** Responses based on actual documentation
- **Parseable:** Structured JSON for downstream processing

---

## ğŸ“ Design Decisions

### Why FAISS?
- **Fast:** Optimized for billion-scale similarity search
- **Simple:** No external database server required
- **Battle-Tested:** Used by Facebook, Spotify, Airbnb
- **Persistent:** Can save/load index to disk

### Why Hybrid Search?
- **Semantic Search:** Finds conceptually similar content
- **Keyword Search (BM25):** Finds exact term matches
- **Cross-Encoder Reranking:** Improves final ranking
- **Result:** Better retrieval accuracy than either alone

### Why Semantic Chunking?
- **Topic-Aware:** Splits at semantic boundaries, not arbitrary character limits
- **Context Preservation:** Keeps related information together
- **Better Retrieval:** More meaningful chunks = better search results

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- [OpenAI](https://openai.com/) for GPT models
- [FAISS](https://faiss.ai/) by Facebook AI for vector search
- [Sentence Transformers](https://www.sbert.net/) for embeddings
- [FastAPI](https://fastapi.tiangolo.com/) for the web framework
- [Streamlit](https://streamlit.io/) for the UI framework

---

## ğŸ“§ Contact

**Kaxit Pandya** - [GitHub](https://github.com/KaxitPandya)

**Project Link:** [https://github.com/KaxitPandya/ai-support-agent](https://github.com/KaxitPandya/ai-support-agent)

---

<div align="center">

**â­ Star this repo if you find it helpful!**

Built with â¤ï¸ using OpenAI, FAISS, FastAPI, and Streamlit

</div>
