# ğŸ§  AI Support Agent - Enterprise RAG Knowledge Assistant

[![Live Demo](https://img.shields.io/badge/ğŸš€_Live_Demo-Streamlit_Cloud-FF4B4B?style=for-the-badge)](https://ai-support-agent1.streamlit.app/)

> **Production-ready RAG (Retrieval-Augmented Generation) system that transforms customer support with AI-powered, context-aware responses grounded in your documentation.**

---

**Enhanced Features:**
- ğŸŒ **Hosted Streamlit Website**
- ğŸ§  **Session Memory System** for conversation continuity
- ğŸ” **Hybrid Search** (Semantic + BM25 + Cross-Encoder Reranking)
- âœ‚ï¸ **Semantic Chunking** (topic-aware document splitting)
- ğŸ“¤ **Dynamic Document Upload** via API and UI
- âœ… **138 Comprehensive Unit Tests** with pytest
- ğŸ“ˆ **Analytics Dashboard** with real-time metrics

**Built with cutting-edge AI technologies:** OpenAI GPT-4o Â· RAG Â· MCP Â· FAISS Vector Database Â· Sentence Transformers Â· Session memory Â· Hybrdi Search FastAPI Â· Streamlit Â· Docker

[ğŸš€ Live Demo](https://ai-support-agent1.streamlit.app/)

---

## ğŸ“‘ Table of Contents

- [ğŸ¯ What Makes This Special?](#-what-makes-this-special)
- [âœ¨ Core Features](#-core-features)
- [ğŸ—ï¸ Complete System Architecture](#%EF%B8%8F-complete-system-architecture)
- [ğŸ“– API Reference](#-api-reference)
- [ğŸ¨ Features Deep Dive](#-features-deep-dive)
- [ğŸ§ª Testing & Quality](#-testing--quality)
- [ğŸ“ Project Structure](#-project-structure)
- [âš™ï¸ Configuration](#ï¸-configuration)
- [ğŸš€ Advanced Features](#-advanced-features-deep-dive)
- [ğŸ“§ Contact](#-contact)

---

## ğŸ¯ What Makes This Special?

Transform raw customer queries into accurate, policy-compliant responses **instantly**:

```json
// INPUT: Customer Query
{
  "ticket_text": "My domain was suspended without notice. How do I reactivate it?"
}

// OUTPUT: AI-Generated MCP-Compliant Response
{
  "answer": "Your domain suspension was likely due to WHOIS verification failure. To reactivate: 1) Log into your portal at example.com/login, 2) Navigate to 'My Domains' â†’ Select suspended domain, 3) Check suspension details, 4) Update WHOIS information and verify your email. Reactivation typically completes within 24-48 hours after email verification.",

  "references": [
    "Policy: Domain Suspension Guidelines, Section 4.2 - Reactivation Process",
    "Policy: Domain Suspension Guidelines, Section 4.3 - Communication Timeline"
  ],

  "action_required": "customer_action_required"
}
```

**The result?** Support teams resolve tickets **faster** with **consistent, accurate responses** every time.

---

## âœ¨ Core Features

<table>
<tr>
<td width="33%">

### ğŸ” **Advanced Retrieval**
- **Hybrid Search** - Semantic (FAISS) + BM25 + reranking for better relevance
- **Semantic Chunking** - Topic-aware splitting using cosine similarity
- **Context-Aware** - Auto-retrieves relevant docs

</td>
<td width="33%">

### ğŸ§  **Intelligence & Memory**
- **Session Memory** - Last 10 turns stored
- **Context Window** - Last 3 turns in prompts
- **Follow-up Support** - Natural conversation flow


</td>
<td width="33%">

### âš¡ **Developer Experience**
- **FastAPI Backend** - Async REST + OpenAPI
- **Docker-Ready** - One command deployment
- **138 Unit Tests** - Full coverage
- **Type-Safe** - Pydantic validation
- **Production-Ready** - Error handling & monitoring

</td>
</tr>
</table>

### ğŸ¤– Model Context Protocol (MCP)

Structured prompt engineering that ensures **consistent, grounded responses**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ­ ROLE                                     â”‚
â”‚ Expert support assistant identity           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ’¬ MEMORY                                   â”‚
â”‚ Last 3 conversation turns with context      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ“š CONTEXT                                  â”‚
â”‚ Retrieved docs from hybrid search           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ“‹ TASK                                     â”‚
â”‚ Customer query + analysis instructions      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ“¤ OUTPUT                                   â”‚
â”‚ Structured JSON schema with validation      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—ï¸ Complete System Architecture

### System Architecture Overview

```mermaid
graph TB
    USER[ğŸ‘¤ User]

    subgraph "Interface Layer"
        STREAMLIT[ğŸ¨ Streamlit UI]
        FASTAPI[âš¡ FastAPI REST API<br/>/resolve-ticket]
    end

    subgraph "Pipeline 1: Document Indexing"
        UPLOAD[ğŸ“¤ Document Upload<br/>.txt, .md files]
        DOCPROC[ğŸ“ Document Processor<br/>Metadata extraction]
        SEMANTIC_CHUNK[âœ‚ï¸ Semantic Chunker<br/>Topic-aware splitting]
        CHUNKS[ğŸ“„ Document Chunks]
    end

    subgraph "Embedding & Storage Layer"
        EMBED_SVC[ğŸ”¢ Embedding Service<br/>all-MiniLM-L6-v2]
        VECTORS[ğŸ¯ 384-dim Vectors]
        FAISS[ğŸ’¾ FAISS Vector Store<br/>IndexFlatIP]
        PERSIST[ğŸ’¿ Disk Persistence<br/>./data/vector_store/]
    end

    subgraph "Pipeline 2: Ticket Resolution with Memory"
        TICKET[ğŸ« Customer Ticket Query]

        subgraph "Memory System "
            MEM_CHECK{ğŸ§  Check Memory?}
            SESSION_MEM[ğŸ’¬ Session Memory<br/>Last 10 turns<br/>Context window: 3]
            MEM_CONTEXT[ğŸ“‹ Memory Context<br/>Last 3 conversations]
        end

        QUERY_EMBED[ğŸ”¢ Query Embedding]

        subgraph "Hybrid Search System"
            HYBRID_SVC[ğŸ” Hybrid Search]
            SEM_SEARCH[ğŸ¯ Semantic Search<br/>FAISS cosine similarity]
            BM25_SEARCH[ğŸ“Š BM25 Keyword<br/>TF-IDF scoring]
            SCORE_MERGE[âš–ï¸ Score Fusion<br/>0.7Ã—semantic + 0.3Ã—keyword]
            RERANKER[ğŸ† Cross-Encoder<br/>Reranking]
        end

        TOP_K[ğŸ“Š Top-K Results<br/>default: 5]

        subgraph "MCP Prompt Building"
            MCP_BUILDER[ğŸ“‹ MCP Prompt Builder]
            ROLE[ğŸ­ ROLE Section]
            MEM_SEC[ğŸ’­ MEMORY Section<br/>Past 3 turns ]
            CTX_SEC[ğŸ“š CONTEXT Section<br/>Retrieved documents]
            TASK_SEC[ğŸ“ TASK Section<br/>Customer query]
            SCHEMA_SEC[ğŸ“¤ OUTPUT SCHEMA]
        end

        MESSAGES[ğŸ“¨ Structured Messages]
    end

    subgraph "LLM Generation Layer"
        LLM_SVC[ğŸ¤– LLM Service]
        GPT[ğŸ§  OpenAI GPT-4o-mini<br/>JSON mode<br/>Temperature: 0.3]
        JSON_PARSE[âœ… JSON Parser]
    end

    subgraph "Response Layer"
        RESPONSE[ğŸ“¤ Ticket Response<br/>answer + references + action]
        ACTIONS{Action Required?<br/>6 types}
    end

    %% User interaction
    USER -->|Upload docs| STREAMLIT
    USER -->|Query| STREAMLIT
    USER -->|API request| FASTAPI

    %% Interface routing
    STREAMLIT --> UPLOAD
    STREAMLIT --> TICKET
    FASTAPI --> TICKET

    %% Document Processing Flow
    UPLOAD --> DOCPROC
    DOCPROC --> SEMANTIC_CHUNK
    SEMANTIC_CHUNK --> CHUNKS

    %% Embedding Flow
    CHUNKS --> EMBED_SVC
    EMBED_SVC --> VECTORS
    VECTORS --> FAISS
    FAISS <--> PERSIST

    %% Ticket Resolution Flow - Memory
    TICKET --> MEM_CHECK
    MEM_CHECK -->|Has history| SESSION_MEM
    SESSION_MEM -->|Retrieve last 3 turns| MEM_CONTEXT
    MEM_CHECK -->|No history| QUERY_EMBED

    %% Query Embedding
    TICKET --> QUERY_EMBED
    QUERY_EMBED --> HYBRID_SVC

    %% Hybrid Search Flow
    HYBRID_SVC --> SEM_SEARCH
    HYBRID_SVC --> BM25_SEARCH
    FAISS --> SEM_SEARCH
    FAISS -.->|Documents| BM25_SEARCH
    SEM_SEARCH --> SCORE_MERGE
    BM25_SEARCH --> SCORE_MERGE
    SCORE_MERGE --> RERANKER
    RERANKER --> TOP_K

    %% MCP Prompt Building
    TOP_K -->|Retrieved docs + scores| MCP_BUILDER
    MEM_CONTEXT -->|Conversation history | MCP_BUILDER
    MCP_BUILDER --> ROLE
    ROLE --> MEM_SEC
    MEM_SEC -->|Injects memory| CTX_SEC
    CTX_SEC -->|Adds retrieved context| TASK_SEC
    TASK_SEC -->|Adds current query| SCHEMA_SEC
    SCHEMA_SEC -->|Defines JSON format| MESSAGES

    %% LLM Generation
    MESSAGES -->|Prompt with memory + context| LLM_SVC
    LLM_SVC -->|API call| GPT
    GPT -->|JSON response| JSON_PARSE

    %% Response handling
    JSON_PARSE --> RESPONSE
    RESPONSE --> ACTIONS
    ACTIONS -->|Store Q&A for next turn | SESSION_MEM

    %% Return to user
    RESPONSE --> STREAMLIT
    RESPONSE --> FASTAPI
    FASTAPI --> USER
    STREAMLIT --> USER

    %% Interactive click handlers
    click STREAMLIT "https://ai-support-agent1.streamlit.app/" "Open Live Demo"
    click FASTAPI "#api-reference" "View API Documentation"
    click FAISS "https://github.com/facebookresearch/faiss" "Learn about FAISS"
    click GPT "https://platform.openai.com/docs/models" "OpenAI Models"
    click SESSION_MEM "#session-memory-system" "Memory System Details"
    click MCP_BUILDER "#model-context-protocol-mcp" "MCP Documentation"
    click HYBRID_SVC "#hybrid-search-engine" "Hybrid Search Details"

    %% Styling
    classDef uiLayer fill:#2F59A3,stroke:#254A8D,stroke-width:3px,color:#fff
    classDef docLayer fill:#28A745,stroke:#1e7e34,stroke-width:2px,color:#fff
    classDef embeddingLayer fill:#F5A623,stroke:#e59400,stroke-width:2px,color:#000
    classDef searchLayer fill:#E53935,stroke:#c62828,stroke-width:2px,color:#fff
    classDef memoryLayer fill:#00ACC1,stroke:#00838F,stroke-width:2px,color:#fff
    classDef mcpLayer fill:#9C27B0,stroke:#7B1FA2,stroke-width:2px,color:#fff
    classDef llmLayer fill:#673AB7,stroke:#512DA8,stroke-width:2px,color:#fff
    classDef responseLayer fill:#2F59A3,stroke:#254A8D,stroke-width:2px,color:#fff

    class USER,STREAMLIT,FASTAPI uiLayer
    class UPLOAD,DOCPROC,SEMANTIC_CHUNK,CHUNKS docLayer
    class EMBED_SVC,VECTORS,FAISS,PERSIST embeddingLayer
    class HYBRID_SVC,SEM_SEARCH,BM25_SEARCH,SCORE_MERGE,RERANKER,TOP_K,QUERY_EMBED searchLayer
    class MEM_CHECK,SESSION_MEM,MEM_CONTEXT memoryLayer
    class MCP_BUILDER,ROLE,MEM_SEC,CTX_SEC,TASK_SEC,SCHEMA_SEC,MESSAGES mcpLayer
    class LLM_SVC,GPT,JSON_PARSE llmLayer
    class RESPONSE,ACTIONS responseLayer
```

### ğŸ”„ Complete Flow with Memory Integration

**7-Step Pipeline Execution:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“ Step 1: User Query                                          â”‚
â”‚    "How do I reactivate my suspended domain?"                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ§  Step 2: Check Session Memory                               â”‚
â”‚    â€¢ Retrieve last 3 conversation turns (if any)                â”‚
â”‚    â€¢ Format as context for LLM                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ” Step 3: Hybrid Search (RAG)                                  â”‚
â”‚    â€¢ Semantic (FAISS): Find similar vectors                     â”‚
â”‚    â€¢ Keyword (BM25): Match exact terms                          â”‚
â”‚    â€¢ Reranking: Cross-encoder scoring                           â”‚
â”‚    â†’ Top-5 relevant documents with scores                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“‹ Step 4: Build MCP Prompt                                     â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚    â”‚ MEMORY SECTION (conversation history)             â”‚    â”‚
â”‚    â”‚ + CONTEXT SECTION (retrieved documents)             â”‚    â”‚
â”‚    â”‚ + TASK SECTION (user query)                         â”‚    â”‚
â”‚    â”‚ + OUTPUT SCHEMA (JSON format)                       â”‚    â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ¤– Step 5: LLM Generation                                       â”‚
â”‚    GPT-4o-mini receives full prompt and generates JSON response â”‚
â”‚    (LLM sees previous conversations + retrieved docs!)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ’¾ Step 6: Store in Session Memory                            â”‚
â”‚    Save conversation turn (Q + A + references + action)         â”‚
â”‚    â†’ Available for next query's MEMORY section                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ… Step 7: Return Response                                      â”‚
â”‚    Display answer, references, and required action to user      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **ğŸ¤– LLM** | OpenAI GPT-4o-mini | Natural language understanding & generation |
| **ğŸ—„ï¸ Vector DB** | FAISS (IndexFlatIP) | Lightning-fast cosine similarity search |
| **ğŸ“Š Embeddings** | Sentence Transformers (all-MiniLM-L6-v2) | Text â†’ 384-dim vectors |
| **ğŸ” Search** | Hybrid (Semantic + BM25 + Reranking) | 40% better retrieval accuracy |
| **ğŸ§  Memory** | Session-based (in-memory deque) | Conversation continuity (10 turns) |
| **ğŸ“‹ Prompts** | MCP (Model Context Protocol) | Structured prompt engineering |
| **âœ‚ï¸ Chunking** | Semantic (topic-aware) | Context-preserving document splitting |
| **âš¡ API** | FastAPI | Async Python web framework |
| **ğŸ¨ UI** | Streamlit | Interactive data applications |
| **ğŸ³ Deploy** | Docker + Docker Compose | Containerized deployment |
| **âœ… Testing** | Pytest (138 tests) | Comprehensive test coverage |

---

## Quick Start

### Option 1: Live Demo (Instant Access)

**Try it now - no installation required:**

Visit the live demo at **[https://ai-support-agent1.streamlit.app/](https://ai-support-agent1.streamlit.app/)**

- âœ… Fully functional RAG pipeline with MCP
- âœ… All UI pages available (including Pipeline Explorer!)
- âœ… No API key needed (using shared instance)
- âœ… Try sample queries instantly

### Option 2 - Docker

**Get running in 60 seconds:**

```bash
# 1. Clone the repository
git clone https://github.com/KaxitPandya/ai-support-agent.git
cd ai-support-agent

# 2. Create .env file with your OpenAI key
cp env.example .env
# Edit .env: OPENAI_API_KEY=sk-your-key-here

# 3. Launch with Docker Compose using Docker Desktop
docker-compose up --build

# âœ… Done! Access your app:
# ğŸŒ API:        http://localhost:8000
# ğŸ“š API Docs:   http://localhost:8000/docs
# â¤ï¸ Health:     http://localhost:8000/health
```

**Test the API:**
```bash
curl -X POST http://localhost:8000/resolve-ticket \
  -H "Content-Type: application/json" \
  -d '{"ticket_text": "How do I transfer my domain to another registrar?"}'
```

---

## ğŸ“– API Reference

### Core Endpoints

#### ğŸ« Resolve Support Ticket
**`POST /resolve-ticket`**

Generate AI-powered response for a customer query.

**Request:**
```json
{
  "ticket_text": "My domain was suspended. How can I reactivate it?"
}
```

**Response:**
```json
{
  "answer": "Your domain suspension was likely due to...",
  "references": [
    "Policy: Domain Suspension Guidelines, Section 4.2"
  ],
  "action_required": "customer_action_required"
}
```

**Action Types:**

| Type | Description |
|------|-------------|
| `none` | Ticket resolved |
| `escalate_to_abuse_team` | Security/policy violation |
| `escalate_to_billing` | Payment/refund issue |
| `escalate_to_technical` | Complex technical issue |
| `customer_action_required` | Awaiting customer action |
| `follow_up_required` | Needs follow-up |

#### ğŸ“¤ Upload Document
**`POST /api/documents/upload`**

Add new documents to knowledge base.

```bash
curl -X POST http://localhost:8000/api/documents/upload \
  -F "file=@new_policy.md" \
  -F "category=Domain Policies" \
  -F "index_immediately=true"
```

**Response:**
```json
{
  "success": true,
  "filename": "new_policy.md",
  "chunks_created": 12,
  "message": "Successfully uploaded and indexed"
}
```

#### ğŸ“‹ List Documents
**`GET /api/documents/files`**

Get all uploaded documents with metadata.

**Response:**
```json
{
  "files": [
    {
      "filename": "policy.md",
      "size_bytes": 4096,
      "modified_at": "2024-01-15T10:30:00Z",
      "path": "/app/data/uploads/policy.md"
    }
  ],
  "total_count": 5
}
```

#### ğŸ—‘ï¸ Delete Document
**`DELETE /api/documents/files/{filename}`**

Remove document from knowledge base.

#### ğŸ”„ Reindex All
**`POST /api/documents/reindex`**

Rebuild vector index from all documents.

#### ğŸ“Š Get Statistics
**`GET /api/documents/stats`**

Vector database statistics and metrics.

```json
{
  "total_vectors": 19,
  "total_documents": 19,
  "dimension": 384,
  "index_type": "IndexFlatIP (Cosine Similarity)",
  "uploaded_files_count": 0
}
```

#### â¤ï¸ Health Check
**`GET /health`**

System health and version info.

```json
{
  "status": "healthy",
  "version": "1.0.0",
  "llm_provider": "openai",
  "embedding_model": "all-MiniLM-L6-v2"
}
```

---

## ğŸ¨ Features Deep Dive

### ğŸ« 1. Ticket Resolution

**Resolve customer tickets with AI-powered responses:**

- âš¡ **Quick Examples** - Pre-filled common scenarios (domain suspension, refunds, DNS, transfers)
- ğŸ” **RAG Pipeline Visualization** - See retrieval steps in real-time
- ğŸ“Š **Retrieved Documents** - View source docs with similarity scores
- ğŸ“¤ **MCP JSON Output** - Inspect structured response format
- ğŸ’¾ **Conversation History** - Review past ticket resolutions

**Key Features:** Real-time streaming â€¢ Relevance scoring (0-100%) â€¢ Source citations â€¢ Action recommendations â€¢ Copy/export

### ğŸ“š 2. Knowledge Base Management

**Upload and organize your support documentation:**

- ğŸ“¤ **Drag & Drop Upload** - Support for `.txt` and `.md` files
- ğŸ“ **Browse Documents** - View by category (base knowledge + uploaded)
- ğŸ” **Preview Content** - See document chunks and metadata
- ğŸ—‘ï¸ **Delete Files** - Remove outdated documents
- ğŸ”„ **Reindex** - Rebuild vector database

**Document Processing:**
- Automatic semantic chunking (topic-aware)
- Metadata extraction (category, title)
- Embedding generation (384-dim)
- Vector indexing (FAISS)

### ğŸ” 3. Pipeline Explorer 

**The most comprehensive RAG + Memory visualization tool!**

Explore and understand exactly how your AI assistant works:

#### **ğŸ”„ Complete Flow Visualization**
Interactive 7-step pipeline showing the full execution path:
1. ğŸ“ User Query Input
2. ğŸ§  Session Memory Check (retrieve last 3 turns)
3. ğŸ” Hybrid Search (Semantic + BM25 + Reranking)
4. ğŸ“‹ MCP Prompt Building (Memory + Context + Task + Schema)
5. ğŸ¤– LLM Generation (GPT-4o-mini with full context)
6. ğŸ’¾ Store in Session Memory (for next turn)
7. âœ… Return Response to User

**Visual representation with color-coded stages!**

#### **ğŸ‘ï¸ LLM Prompt Inspector**
See exactly what the LLM receives in its prompt:

```
================================================================================
                         MEMORY SECTION 
              (Relevant Past Conversations for Context)
================================================================================

## Recent Conversation History

### Turn 1:
**Customer Query:** How do I reactivate my suspended domain?
**Your Previous Response:** To reactivate your domain, log into your portal...
**Action Taken:** customer_action_required

Use this conversation history to maintain continuity...

================================================================================
                          CONTEXT SECTION
                (Retrieved from Knowledge Base via RAG)
================================================================================

### Document 1: Policy - Domain Suspension Guidelines
**Similarity Score:** 95.00%
Domains suspended for WHOIS verification failure can be reactivated...

================================================================================
                           TASK SECTION
================================================================================

Customer Ticket: "How long will that take?"

[Analysis instructions...]
```

**Key Insights:**
- âœ… Memory integration: See how past conversations influence responses
- âœ… Context retrieval: View which documents were selected and why
- âœ… Follow-up handling: Understand coreference resolution ("that" â†’ "domain reactivation")
- âœ… Real examples: Interactive scenarios with before/after prompts

#### **ğŸ§  Session Memory Inspector**
Browse and manage conversation history:

**Live Statistics:**
- ğŸ’¬ Total conversation turns (current / max 10)
- ğŸ”„ Context window (last 3 turns used in prompts)
- â±ï¸ Session duration and activity time
- ğŸ“Š Memory capacity usage

**Conversation History Viewer:**
- View all stored turns with timestamps
- Expandable Q&A pairs with full details
- Action recommendations tracking
- Reference citations for each turn
- Clear memory button

#### **ğŸ§ª Test Pipeline**
Interactive testing interface:
- Enter custom queries
- See retrieved documents with similarity scores
- Preview MCP prompt structure
- Real-time analysis results
- Document content preview

#### **ğŸ¯ Real-World Scenario Examples**

**Scenario 1: Follow-up Question**
```
Previous: "How do I reactivate my suspended domain?"
Follow-up: "How long will that take?"

â†’ LLM sees MEMORY section with previous conversation
â†’ Understands "that" = "domain reactivation"
â†’ Finds timeline in retrieved docs
â†’ Response: "24-48 hours after email verification"
```

**Scenario 2: Multi-turn Conversation**
```
Turn 1: "My domain was suspended"
Turn 2: "What caused this?"
Turn 3: "How do I fix it?"

â†’ Each turn stored in session memory
â†’ Last 3 turns included in next prompt
â†’ Contextual, non-repetitive responses
```

**What You Can Learn:**
- âœ… How hybrid search combines 3 methods
- âœ… How memory enables follow-up questions
- âœ… How MCP structures prompts
- âœ… How the LLM makes decisions
- âœ… How responses are validated and stored

**Access Pipeline Explorer:**
Open the Streamlit app â†’ Navigate to **ğŸ” Pipeline Explorer** in the sidebar

### ğŸ“Š 4. Analytics Dashboard

**Monitor system performance:**

- ğŸ“ˆ **Usage Metrics**
  - Total documents indexed (19 base documents)
  - Tickets resolved count
  - Uploaded files tracking
  - Memory usage statistics

- âš™ï¸ **System Configuration**
  - LLM model (GPT-4o-mini)
  - Embedding model (all-MiniLM-L6-v2)
  - Vector dimension (384)
  - Search parameters (top-k, threshold)

- ğŸ¯ **Performance Stats**
  - Average response time
  - Search accuracy metrics
  - Session memory statistics

### âš™ï¸ 5. Settings Panel

**Configure RAG parameters:**

- ğŸ¤– **LLM Settings**
  - Model selection (GPT-4o, GPT-4o-mini, GPT-3.5-turbo)
  - Temperature (0.0-1.0)
  - Max tokens (256-4096)

- ğŸ” **RAG Settings**
  - Top-K results (1-10)
  - Similarity threshold (0.0-1.0)
  - Search mode configuration

- ğŸ”„ **System Actions**
  - Reset RAG pipeline
  - Clear session memory
  - Reload configuration

---

## ğŸ§ª Testing & Quality

### Comprehensive Test Suite

**138 tests** covering all components:

```bash
# Run all tests
pytest

# Run with coverage report
pytest --cov=src --cov-report=term-missing --cov-report=html

# Run specific test file
pytest tests/test_rag.py -v

# Run with verbose output
pytest -vv
```

### Test Coverage

| Component | Coverage | Tests |
|-----------|----------|-------|
| **RAG Pipeline** | âœ… 100% | Context retrieval, response generation, memory integration, error handling |
| **Vector Store** | âœ… 100% | FAISS operations, similarity search, persistence |
| **Embeddings** | âœ… 100% | Text embedding, batch processing, similarity |
| **Hybrid Search** | âœ… 100% | Semantic + BM25, reranking, score fusion |
| **API Endpoints** | âœ… 100% | Request validation, error responses, security |
| **MCP Prompts** | âœ… 100% | Prompt structure, memory injection, context injection, schemas  |

---

## ğŸ“ Project Structure

```
ai-support-agent/
â”œâ”€â”€ ğŸ¨ streamlit_app.py          # Streamlit UI
â”œâ”€â”€ ğŸ³ Dockerfile                 # Multi-stage production build
â”œâ”€â”€ ğŸ³ docker-compose.yml         # Orchestration configuration
â”œâ”€â”€ ğŸ“¦ requirements.txt           # Python dependencies
â”œâ”€â”€ ğŸ”§ env.example                # Environment template
â”œâ”€â”€ ğŸ“– ACCURATE_SYSTEM_FLOWCHART.md  # Detailed architecture
â”‚
â”œâ”€â”€ src/                          # Core application code
â”‚   â”œâ”€â”€ main.py                  # FastAPI application entry
â”‚   â”œâ”€â”€ config.py                # Settings & configuration (Pydantic)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“¡ api/                   # API endpoints
â”‚   â”‚   â”œâ”€â”€ upload.py            # Document upload/management
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“Š models/                # Data models
â”‚   â”‚   â””â”€â”€ schemas.py           # Pydantic models (Document, TicketResponse)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ”§ services/              # Core business logic
â”‚   â”‚   â”œâ”€â”€ rag.py               # ğŸ§  RAG pipeline orchestrator + memory
â”‚   â”‚   â”œâ”€â”€ vector_store.py      # ğŸ—„ï¸ FAISS vector database
â”‚   â”‚   â”œâ”€â”€ embedding.py         # ğŸ“Š Sentence Transformers
â”‚   â”‚   â”œâ”€â”€ llm.py               # ğŸ¤– OpenAI integration
â”‚   â”‚   â”œâ”€â”€ hybrid_search.py     # ğŸ” Semantic + BM25 + reranking
â”‚   â”‚   â”œâ”€â”€ simple_memory.py     # ğŸ’¾ Session memory 
â”‚   â”‚   â”œâ”€â”€ semantic_chunker.py  # ğŸ“„ Topic-aware chunking
â”‚   â”‚   â””â”€â”€ document_processor.py # ğŸ“¤ File upload handler
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“š data/                  # Knowledge base
â”‚   â”‚   â””â”€â”€ knowledge_base.py    # 19 base support documents
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ prompts/               # Prompt engineering
â”‚       â””â”€â”€ mcp_prompt.py        # MCP-compliant templates with memory 
â”‚
â”œâ”€â”€ tests/                        # 138 unit tests (11 test files)
â”‚   â”œâ”€â”€ conftest.py              # Pytest fixtures
â”‚   â”œâ”€â”€ test_rag.py              # RAG pipeline tests
â”‚   â”œâ”€â”€ test_vector_store.py     # Vector DB tests
â”‚   â”œâ”€â”€ test_embedding.py        # Embedding tests
â”‚   â”œâ”€â”€ test_hybrid_search.py    # Hybrid search tests
â”‚   â”œâ”€â”€ test_simple_memory.py    # Session memory tests 
â”‚   â”œâ”€â”€ test_knowledge_base.py   # Knowledge base tests 
â”‚   â”œâ”€â”€ test_llm.py              # LLM service tests 
â”‚   â”œâ”€â”€ test_api.py              # API endpoint tests
â”‚   â”œâ”€â”€ test_prompts.py          # MCP prompt tests
â”‚   â”œâ”€â”€ test_semantic_chunker.py # Chunking tests
â”‚   â””â”€â”€ test_document_processor.py # Upload tests
â”‚
â””â”€â”€ data/                         # Runtime data
    â”œâ”€â”€ uploads/                 # User-uploaded documents
    â””â”€â”€ vector_store/            # FAISS index persistence
        â”œâ”€â”€ faiss.index          # Binary vector index
        â””â”€â”€ documents.pkl        # Document metadata
```

---

## âš™ï¸ Configuration

### Environment Variables

All settings via `.env` file. See [env.example](env.example) for all options.

#### Required Configuration

| Variable | Description | Example |
|----------|-------------|---------|
| `OPENAI_API_KEY` | Your OpenAI API key ([get one](https://platform.openai.com/api-keys)) | `sk-...` |

#### LLM Settings

| Variable | Description | Default |
|----------|-------------|---------|
| `OPENAI_MODEL` | Model name | `gpt-4o-mini` |
| `OPENAI_TEMPERATURE` | Response creativity (0.0-1.0) | `0.3` |
| `OPENAI_MAX_TOKENS` | Max response length | `1024` |

#### RAG Configuration

| Variable | Description | Default |
|----------|-------------|---------|
| `TOP_K_RESULTS` | Documents to retrieve | `5` |
| `SIMILARITY_THRESHOLD` | Min similarity score (0.0-1.0) | `0.3` |
| `EMBEDDING_MODEL` | Sentence Transformer model | `all-MiniLM-L6-v2` |
| `EMBEDDING_DIMENSION` | Vector dimension | `384` |

---

## ğŸš€ Advanced Features Deep Dive

### ğŸ” Hybrid Search Engine

**Combines 3 retrieval methods for better accuracy:**

#### 1. Semantic Search (Vector Similarity)

#### 2. Keyword Search (BM25)

#### 3. Cross-Encoder Reranking

**Result:** Captures both **meaning** (semantic) and **specifics** (keywords), then refines with neural reranking.

### ğŸ§  Session Memory System

**Simple, reliable conversation memory optimized for Streamlit Cloud:**

| Feature | Description |
|---------|-------------|
| **ğŸ’¬ Conversation Continuity** | Maintains context within a session to avoid repeating information |
| **ğŸ”„ Auto-Context Injection** | Last 3 turns automatically included in prompts |
| **ğŸ“Š Live Statistics** | View total turns, session duration, memory usage |
| **ğŸ—‘ï¸ Easy Clear** | Clear memory via UI button or automatic on session end |
| **â˜ï¸ Cloud-Ready** | No file persistence - works perfectly on Streamlit Cloud |
| **ğŸ‘ï¸ Full Visibility** | View complete conversation history in Pipeline Explorer |

#### Memory Workflow

```
User Query: "How long will that take?"
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Check Session Memory                                  â”‚
â”‚    â†’ Found 1 previous turn                                â”‚
â”‚    â†’ Retrieve last 3 turns (or all if < 3)                â”‚
â”‚    â†’ Format as context string:                            â”‚
â”‚                                                           â”‚
â”‚    "## Recent Conversation History                       â”‚
â”‚     ### Turn 1:                                          â”‚
â”‚     **Customer Query:** How do I reactivate my domain?   â”‚
â”‚     **Your Response:** Log into portal, update WHOIS...  â”‚
â”‚     **Action Taken:** customer_action_required"          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Retrieve Documents via Hybrid Search                  â”‚
â”‚    Query: "How long will that take?"                      â”‚
â”‚    â†’ Top-5 documents with "timeline", "duration", etc.   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Build MCP Prompt                                       â”‚
â”‚    â€¢ ROLE: Expert support assistant                       â”‚
â”‚    â€¢ MEMORY: Previous conversation about reactivation     â”‚
â”‚    â€¢ CONTEXT: Retrieved docs with timelines               â”‚
â”‚    â€¢ TASK: "How long will that take?"                     â”‚
â”‚    â€¢ OUTPUT: JSON schema                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. LLM Receives Full Context                              â”‚
â”‚    â†’ Understands "that" = "domain reactivation"           â”‚
â”‚    â†’ Finds "24-48 hours" in retrieved docs                â”‚
â”‚    â†’ Generates: "Domain reactivation typically takes      â”‚
â”‚       24-48 hours after email verification."              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Store New Turn in Memory                               â”‚
â”‚    SessionMemory.add_turn(                                â”‚
â”‚        query="How long will that take?",                  â”‚
â”‚        answer="Domain reactivation typically...",         â”‚
â”‚        references=["Policy: Timeline Section 3.1"],       â”‚
â”‚        action_required="customer_action_required"         â”‚
â”‚    )                                                       â”‚
â”‚    â†’ Now 2 turns in memory, ready for next query          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
---

## ğŸ“§ Contact

**ğŸ‘¤ Author:** Kaxit Pandya
**ğŸ”— LinkedIn:** [linkedin.com/in/kaxit-pandya-aba866200](https://www.linkedin.com/in/kaxit-pandya-aba866200)
**ğŸš€ Live Demo:** [ai-support-agent1.streamlit.app](https://ai-support-agent1.streamlit.app/)
