# Knowledge Assistant Environment Configuration
# Copy this file to .env and fill in your values

# =================================
# LLM Provider Configuration
# =================================

# LLM provider to use: "openai" or "ollama"
LLM_PROVIDER=openai

# =================================
# OpenAI Configuration
# =================================

# Your OpenAI API key (required if using OpenAI)
OPENAI_API_KEY=sk-your-api-key-here

# OpenAI model to use (e.g., gpt-4o, gpt-4o-mini, gpt-3.5-turbo)
OPENAI_MODEL=gpt-4o-mini

# Temperature for response generation (0.0 = deterministic, 1.0 = creative)
OPENAI_TEMPERATURE=0.3

# Maximum tokens in the response
OPENAI_MAX_TOKENS=1024

# =================================
# Ollama Configuration (Local LLM)
# =================================

# Ollama server URL
OLLAMA_BASE_URL=http://localhost:11434

# Ollama model to use (e.g., llama2, mistral, codellama)
OLLAMA_MODEL=llama2

# =================================
# Embedding Configuration
# =================================

# Sentence Transformer model for embeddings
EMBEDDING_MODEL=all-MiniLM-L6-v2

# =================================
# RAG Configuration
# =================================

# Number of documents to retrieve for context
TOP_K_RESULTS=3

# Minimum similarity score for document retrieval (0.0 - 1.0)
SIMILARITY_THRESHOLD=0.3

# =================================
# Application Settings
# =================================

# Enable debug mode (true/false)
DEBUG=false
